#shell.executable("/bin/bash")
#shell.prefix("source $HOME/.bashrc; ")

#import os

IDS, = glob_wildcards("genomes/{genome_id}.gb") # get all genomes in genomes dir
CAMISIM_DIR = "/home/people/katste/camisim/CAMISIM"

rule camisim_metafiles:
    params:
        genome_files = " ".join(expand('genomes/{genome_ids}.gb', genome_ids=IDS))
    output:
        fastas = expand('camisim_fasta/{genome_ids}.fa', genome_ids=IDS),
        camisim_metafile = 'camisim_configfiles/metadata',
        camisim_genomefile = 'camisim_configfiles/id_to_genome_file',
        camisim_abundance = 'camisim_configfiles/id_to_distributions'
    shell:
        '''module load anaconda3/4.4.0
        python3 /home/projects/cge/data/projects/other/simulatedMAGpipeline/magician/magician/extract_camisim_data.py \
         {params.genome_files} --even_abundance
        '''

rule camisim_configfiles:
    input:
        camisim_metafile = 'camisim_configfiles/metadata',
        camisim_genomefile = 'camisim_configfiles/id_to_genome_file',
        camisim_abundance = 'camisim_configfiles/id_to_distributions'
    params:
        camisim_dir = CAMISIM_DIR,
        coverage = 20
    output:
        camisim_configfile = 'camisim_config_snaked.ini'
    shell:
         '''module load anaconda3/4.4.0
         python3 /home/projects/cge/data/projects/other/simulatedMAGpipeline/magician/magician/generate_camisim_config.py \
         {params.camisim_dir} {input.camisim_metafile} {input.camisim_genomefile} -f {output.camisim_configfile} \
         -a {input.camisim_abundance} -c 20 --read_sim "wgsim" --read_sim_path "{params.camisim_dir}/tools/wgsim/wgsim" \
         --errorfree
         '''

rule run_camisim:
    input:
        camisim_configfile = 'camisim_config_snaked.ini'
    output:
        concat_results_r1 = 'camisim_out/simulated_metagenome_r1.gz',
        concat_results_r2 = 'camisim_out/simulated_metagenome_r2.gz'
    shell:
        '''module load anaconda2/4.4.0
        python2 {CAMISIM_DIR}/metagenomesimulation.py {input.camisim_configfile}
        cat camisim_out/*/reads/*1.fq.gz > {output.concat_results_r1}
        cat camisim_out/*/reads/*2.fq.gz > {output.concat_results_r2}
        '''
#rule cleanup_camisim: TODO! Move old result files, clear out old internal data
#    input:
#        camisim_resultdir = ''

rule fastqc:
    input:
          reads = 'camisim_out/simulated_metagenome_r1.gz'
    output:
          qc_data = 'qc/simulated_metagenome_r1_fastqc.html'
    shell:
         '''module load tools ngs
         module load perl openjdk/14 fastqc/0.11.8
         fastqc -o qc {input.reads}
         '''

# Quality and adapter trim the raw reads
rule trim_bbduk:
    input:
        R1="camisim_out/simulated_metagenome_r1.gz",
        R2="camisim_out/simulated_metagenome_r2.gz"
    output:
        R1="trimReads/simulated_metagenome_r1.trim.fq.gz",
        R2="trimReads/simulated_metagenome_r2.trim.fq.gz",
        RS="trimReads/simulated_metagenome_S.trim.fq.gz"
    threads: 8
    shell:
        '''module load ngs tools
        module load java/1.8.0
        module load bbmap/36.49
        bbduk2.sh -Xmx12g in={input.R1} in2={input.R2} out={output.R1} out2={output.R2} outs={output.RS} overwrite=t minlen=50 qtrim=r trimq=20 k=19 mink=11 threads={threads} rref=adapters.fa
        '''


# Do metagenomic assembly using metaSpades
rule asm_metaspades:
        input:
            R1="trimReads/simulated_metagenome_r1.trim.fq.gz",
            R2="trimReads/simulated_metagenome_r2.trim.fq.gz",
            RS="trimReads/simulated_metagenome_S.trim.fq.gz"
        output:
            fa="metaspades/simulated_scaffolds.fasta"
        params:
            dir="metaspades",
            asm="metaspades/scaffolds.fasta",
            time="time/metaspades/simulated.time"
        log:
            out="logs/asm_metaspades/simulated.out",
            err="logs/asm_metaspades/simulated.err"
        benchmark:
            "benchmarks/simulated.metaspades.bm.txt"
        threads: 20
        shell:
                '''
                module load spades/3.13.0
                mkdir -p "time/metaspades"
                /usr/bin/time -v -o {params.time} metaspades.py -t {threads} -1 {input.R1} -2 {input.R2} -s {input.RS} -o {params.dir} -k 27,47,67,87,107,127 --memory 700 2> {log.err} 1> {log.out}
            mv {params.asm} {output.fa}
                '''

# Clean up after metaspades
# Remove leftover files and compress final output
# Should only run when final metaspades output and some junk is present
rule cleanup_metaspades:
    input:
        dir="metaspades",
        scaf="metaspades/simulated_metagenome.scaf.min1000.fa",
        junk="metaspades/contigs.fasta"
    output:
        cleanup="metaspades/cleanup.txt"
    threads: 8
    shell:
                '''
        rm -f {input.dir}/contigs.paths
        rm -f {input.dir}/scaffolds.paths
        rm -f {input.dir}/first_pe_contigs.fasta
        rm -f {input.dir}/before_rr.fasta
        rm -rf {input.dir}/K27 {input.dir}/K47 {input.dir}/K67 {input.dir}/K87 {input.dir}/K107 {input.dir}/K127 {input.dir}/corrected
        rm -f {input.junk}
        cd {input.dir} && pigz -q -p {threads} *.fasta *.fastg *.gfa && cd ../..
        touch {output.cleanup}
                '''

# Remove small scaffolds and add sample prefix to fasta header
rule filter_scafs:
    input:
        asm="metaspades/simulated_scaffolds.fasta"
    output:
        asm="metaspades/simulated_metagenome.scaf.min1000.fa"
    params:
        pfx="sim" # TODO - include *some* run identifier?
    threads: 1
    shell:
        '''
        rename.sh ow=t fastawrap=60 minscaf=1000 prefix={params.pfx} addprefix=t in={input.asm} out={output.asm}
        '''

# Map reads to assembly to get coverage and depth
rule map_bbmap:
    input:
        R1="trimReads/simulated_metagenome_r1.trim.fq.gz",
        R2="trimReads/simulated_metagenome_r2.trim.fq.gz",
        fa="metaspades/simulated_metagenome.scaf.min1000.fa"
    output:
        outsam="mapped/simulated.sam",
        outbam="mapped/simulated.sort.bam",
        dep="coverage/simulated.txt"
    log:
        out="logs/map_bbmap/simulated.out",
        err="logs/map_bbmap/simulated.err"

    threads: 20
    shell:
            '''module load ngs tools
            module load perl
            module load java/1.8.0
            module load bbmap/36.49
            module load samtools/1.10
            module load metabat/2.12.1
            mkdir -p logs/map_bbmap
            bbmap.sh in={input.R1} in2={input.R2} minid=0.90 threads={threads} ref={input.fa} outm={output.outsam} overwrite=t nodisk=t 2> {log.err} 1> {log.out}
            samtools view -bSh1 {output.outsam} | samtools sort -m 20G -@ 3 > {output.outbam}
            jgi_summarize_bam_contig_depths {output.outbam} --outputDepth {output.dep}
            '''

# Use MetaBat2 to bin scaffolds from sample
rule metabat2:
    input:
        asm="metaspades/simulated_metagenome.scaf.min1000.fa",
        dep="coverage/simulated.txt"
    output:
        "metabat2/simulated.bin"
    params:
        out="metabat2/simulated.bin", # TODO: is this needed?
        time="time/metabat2/simulated.time"
    log:
                out="logs/metabat2/simulated.out",
                err="logs/metabat2/simulated.err"
    benchmark:
                "benchmarks/simulated.metabat2.bm.txt"

    threads: 10
    shell: # TODO - does snakemake generate dirs for logs and such?
        '''
        module load ngs tools
        module load perl
        module load metabat/2.12.1
        mkdir -p logs/metabat2
        mkdir -p time/metabat2
        /usr/bin/time -v -o {params.time} metabat -t {threads} -v -m 1500 --saveCls -i {input.asm} -a {input.dep} -o {params.out} 2> {log.err} 1> {log.out}
        '''

# Use prodigal to find ORFs in the metagenome and save genes and proteins
rule findgenes_prodigal:
    input:
        asm="metaspades/simulated_metagenome.scaf.min1000.fa"
    output:
        fna="genes/simulated_genes.fna",
        faa="genes/simulated_proteins.faa",
        prodi="genes/simulated_prodigal.txt"
    threads: 2
    shell:
        '''
        prodigal -i {input.asm} -p meta -a {output.faa} -d {output.fna} -o {output.prodi}
        '''

# Run checkm on the MAGs to estimate taxonomy and quality
rule checkm:
        input:
                dir="metabat2"
        output:
                txt="checkm/simulated.checkm.txt",
                dir="checkm/simulated.checkm"
        threads: 20
        shell:
                '''
        module unload anaconda3/2.2.0
                module load anaconda2/4.4.0
                module load prodigal/2.6.2
        module load hmmer/3.1b2
        module load pplacer/1.1.alpha17
        checkm lineage_wf -f {output.txt} -t {threads} --pplacer_threads {threads} --tab_table -x fa {input.dir} {output.dir}
        '''
