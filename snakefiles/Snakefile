#shell.executable("/bin/bash")
#shell.prefix("source $HOME/.bashrc; ")

# required: tab-separated file with genbank path to abundance in sample mapping
with open("sample_distributions.tsv", "r") as samples_file:
    SAMPLES = samples_file.readline().strip().split("\t")[1:] # from the header, take all but the first column's names

# Directory containing CAMISIM, change as appropriate
CAMISIM_DIR = "/home/people/katste/camisim/CAMISIM"

rule complete_qc:
    input:
        fastqc = expand("qc/{sample}/simulated_{sample}_r1_fastqc.html", sample=SAMPLES),
        checkm_txt = expand("checkm/{sample}.checkm.txt", sample=SAMPLES),
        checkm_dir = expand("checkm/{sample}.checkm", sample=SAMPLES),
        stat_files = expand("stats/{sample}.tsv", sample=SAMPLES),
        drep_all = expand("drep_genomes/{sample}/figures/Secondary_clustering_dendrograms.pdf", sample=SAMPLES)

rule all_camisim:
    input:
        all_r1 = expand('camisim_out/{sample}/simulated_{sample}_r1.gz', sample=SAMPLES),
        all_r2 = expand('camisim_out/{sample}/simulated_{sample}_r2.gz', sample=SAMPLES)

rule clean_all_camisim:
    input: expand("camisim_old_runs/{sample}/{sample}", sample=SAMPLES)

rule all_qc:
        input: expand("qc/{sample}/simulated_{sample}_r1_fastqc.html", sample=SAMPLES)

rule all_metaspades:
	input: expand("metaspades/{sample}/{sample}_scaffolds.fasta", sample=SAMPLES)

rule make_mags:
	input: expand("metabat2/{sample}/{sample}.bin", sample=SAMPLES)

rule all_checkm:
    input:
        txt=expand("checkm/{sample}.checkm.txt", sample=SAMPLES),
        dir=expand("checkm/{sample}.checkm", sample=SAMPLES)

rule all_stats:
    input:
        stat_files = expand("stats/{sample}.tsv", sample=SAMPLES)

rule pool_bins_and_refs_each_sample:
    input:
        merged=expand("bins_all/{sample}/{sample}", sample=SAMPLES)
        
rule all_drep:
    input: 
        test = expand("drep_genomes/{sample}/figures/Secondary_clustering_dendrograms.pdf", sample=SAMPLES)

rule clean_all_drep:
    input:
        all_checks = expand("drep_old/{sample}/{sample}_move_check", sample=SAMPLES)

# Extract and write metadata
rule camisim_metafiles:
    params:
        sample_col = "{sample}",
        samplefile = "sample_distributions.tsv"
    output:
        camisim_metafile = 'camisim_configfiles/metadata_{sample}',
        camisim_genomefile = 'camisim_configfiles/id_to_genome_file_{sample}',
        camisim_abundance = 'camisim_configfiles/id_to_distributions_{sample}'
    shell:
        '''module load tools
        module load anaconda3/4.4.0
        python3 /home/projects/cge/data/projects/other/simulatedMAGpipeline/magician/camisim_setup/extract_camisim_data.py \
        {params.samplefile} {params.sample_col}
        '''

# Write configuration file for Camisim
rule camisim_configfiles:
    input:
        camisim_metafile = 'camisim_configfiles/metadata_{sample}',
        camisim_genomefile = 'camisim_configfiles/id_to_genome_file_{sample}',
        camisim_abundance = 'camisim_configfiles/id_to_distributions_{sample}'
    params:
        camisim_dir = CAMISIM_DIR,
        coverage = 20
    output:
        camisim_configfile = 'camisim_config_{sample}.ini'
    shell:
         '''module load anaconda3/4.4.0
         python3 /home/projects/cge/data/projects/other/simulatedMAGpipeline/magician/camisim_setup/generate_camisim_config.py \
         {params.camisim_dir} {input.camisim_metafile} {input.camisim_genomefile} -f {output.camisim_configfile} \
         -o "camisim_out/{wildcards.sample}" -a {input.camisim_abundance} -c {params.coverage} --read_sim "wgsim" \
         --read_sim_path "{params.camisim_dir}/tools/wgsim/wgsim" --errorfree \
         '''

# Run CAMISIM on sample, then make one file each with pooled forward & reverse reads
rule run_camisim:
    input:
        camisim_configfile = 'camisim_config_{sample}.ini'
    output:
        concat_results_r1 = 'camisim_out/{sample}/simulated_{sample}_r1.gz',
        concat_results_r2 = 'camisim_out/{sample}/simulated_{sample}_r2.gz'
    shell:
        '''module load anaconda2/4.4.0
        python2 {CAMISIM_DIR}/metagenomesimulation.py {input.camisim_configfile}
        cat camisim_out/{wildcards.sample}/*/reads/*1.fq.gz > {output.concat_results_r1}
        cat camisim_out/{wildcards.sample}/*/reads/*2.fq.gz > {output.concat_results_r2}
        '''

# Move CAMISIM result files, clear out genome locations and metadata
rule cleanup_camisim:
    input:
        camisim_resultdir = "camisim_out/{sample}",
        camisim_result_check = "camisim_out/{sample}/simulated_{sample}_r1.gz"  # check if this has updated
    output:
        camisim_check_old = "camisim_old_runs/{sample}/{sample}"
    shell: '''
        mv {input.camisim_resultdir}/*_*_sample_0 camisim_old_runs/{wildcards.sample}
        rm {input.camisim_resultdir}/internal/genome_locations.tsv
        rm {input.camisim_resultdir}/internal/meta_data.tsv
        touch camisim_old_runs/{wildcards.sample}/{wildcards.sample}
        '''

# Run fastQC on forward/reverse reads
rule fastqc:
    input:
          reads_r1 = 'camisim_out/{sample}/simulated_{sample}_r1.gz',
          reads_r2 = 'camisim_out/{sample}/simulated_{sample}_r2.gz'
    output:
          qc_r1 = 'qc/{sample}/simulated_{sample}_r1_fastqc.html',
          qc_r2 = 'qc/{sample}/simulated_{sample}_r2_fastqc.html'
    shell:
         '''module load tools ngs
         module load perl openjdk/14 fastqc/0.11.8
         fastqc -o qc/{wildcards.sample} {input.reads_r1} {input.reads_r2}
         '''
# ### ADAPTED FROM CODE BY PATRICK MUNK ###
# Quality and adapter trim the raw reads
rule trim_bbduk:
    input:
        R1="camisim_out/{sample}/simulated_{sample}_r1.gz",
        R2="camisim_out/{sample}/simulated_{sample}_r2.gz"
    output:
        R1="trimReads/{sample}/simulated_{sample}_r1.trim.fq.gz",
        R2="trimReads/{sample}/simulated_{sample}_r2.trim.fq.gz",
        RS="trimReads/{sample}/simulated_{sample}_S.trim.fq.gz"
    threads: 8
    shell:
        '''module load ngs tools
        module load java/1.8.0
        module load bbmap/36.49
        bbduk2.sh -Xmx12g in={input.R1} in2={input.R2} out={output.R1} out2={output.R2} outs={output.RS} overwrite=t \
        minlen=50 qtrim=r trimq=20 k=19 mink=11 threads={threads} rref=adapters.fa qin=33
        '''


# Do metagenomic assembly using metaSpades
rule asm_metaspades:
        input:
            R1="trimReads/{sample}/simulated_{sample}_r1.trim.fq.gz",
            R2="trimReads/{sample}/simulated_{sample}_r2.trim.fq.gz",
            RS="trimReads/{sample}/simulated_{sample}_S.trim.fq.gz"
        output:
            fa="metaspades/{sample}/{sample}_scaffolds.fasta"
        params:
            dir="metaspades/{sample}",
            asm="metaspades/{sample}/scaffolds.fasta",
            time="time/metaspades/{sample}.time"
        log:
            out="logs/asm_metaspades/{sample}.out",
            err="logs/asm_metaspades/{sample}.err"
        benchmark:
            "benchmarks/{sample}.metaspades.bm.txt"
        threads: 20
        shell: # specify phred offset - assumed to be 33 for wgsim reads w/o error profile
                '''
                module load spades/3.13.0
                mkdir -p "time/metaspades"
                /usr/bin/time -v -o {params.time} metaspades.py -t {threads} -1 {input.R1} -2 {input.R2} -s {input.RS} \
                -o {params.dir} -k 27,47,67,87,107,127 --memory 120 --phred-offset 33 2> {log.err} 1> {log.out}
            mv {params.asm} {output.fa}
                '''

# Clean up after metaspades
# Remove leftover files and compress final output
# Should only run when final metaspades output and some junk is present
rule cleanup_metaspades:
    input:
        dir="metaspades/{sample}",
        scaf="metaspades/{sample}/simulated_{sample}.scaf.min1000.fa",
        junk="metaspades/{sample}/contigs.fasta"
    output:
        cleanup="metaspades/{sample}/cleanup.txt"
    threads: 8
    shell:
                '''
        rm -f {input.dir}/contigs.paths
        rm -f {input.dir}/scaffolds.paths
        rm -f {input.dir}/first_pe_contigs.fasta
        rm -f {input.dir}/before_rr.fasta
        rm -rf {input.dir}/K27 {input.dir}/K47 {input.dir}/K67 {input.dir}/K87 {input.dir}/K107 {input.dir}/K127 {input.dir}/corrected
        rm -f {input.junk}
        cd {input.dir} && pigz -q -p {threads} *.fasta *.fastg *.gfa && cd ../..
        touch {output.cleanup}
                '''

# Remove small scaffolds and add sample prefix to fasta header
rule filter_scafs:
    input:
        asm="metaspades/{sample}/{sample}_scaffolds.fasta"
    output:
        asm="metaspades/{sample}/simulated_{sample}.scaf.min1000.fa"
    params:
        pfx="{sample}" 
    threads: 1
    shell:
        '''module load ngs tools
        module load jdk/14
        module load bbmap/36.49
        rename.sh ow=t fastawrap=60 minscaf=1000 prefix={params.pfx} addprefix=t in={input.asm} out={output.asm}
        '''

# Map reads to assembly to get coverage and depth
rule map_bbmap:
    input:
        R1="trimReads/{sample}/simulated_{sample}_r1.trim.fq.gz",
        R2="trimReads/{sample}/simulated_{sample}_r2.trim.fq.gz",
        fa="metaspades/{sample}/simulated_{sample}.scaf.min1000.fa"
    output:
        outsam="mapped/{sample}.sam",
        outbam="mapped/{sample}.sort.bam",
        dep="coverage/{sample}.txt"
    log:
        out="logs/map_bbmap/{sample}.out",
        err="logs/map_bbmap/{sample}.err"

    threads: 20
    shell:
            '''module load ngs tools
            module load perl
            module load java/1.8.0
            module load bbmap/36.49
            module load samtools/1.10
            module load metabat/2.12.1
            mkdir -p logs/map_bbmap
            bbmap.sh in={input.R1} in2={input.R2} minid=0.90 threads={threads} ref={input.fa} outm={output.outsam} overwrite=t nodisk=t 2> {log.err} 1> {log.out}
            samtools view -bSh1 {output.outsam} | samtools sort -m 20G -@ 3 > {output.outbam}
            jgi_summarize_bam_contig_depths {output.outbam} --outputDepth {output.dep}
            '''

# Use MetaBat2 to bin scaffolds from sample
rule metabat2:
    input:
        asm="metaspades/{sample}/simulated_{sample}.scaf.min1000.fa",
        dep="coverage/{sample}.txt"
    output:
        "metabat2/{sample}/{sample}.bin"
    params:
        out="metabat2/{sample}/{sample}.bin",
        time="time/metabat2/{sample}.time"
    log:
                out="logs/metabat2/{sample}.out",
                err="logs/metabat2/{sample}.err"
    benchmark:
                "benchmarks/{sample}.metabat2.bm.txt"

    threads: 10
    shell:
        '''
        module load ngs tools
        module load perl
        module load metabat/2.12.1
        mkdir -p logs/metabat2
        mkdir -p time/metabat2
        /usr/bin/time -v -o {params.time} metabat -t {threads} -v -m 1500 --saveCls -i {input.asm} -a {input.dep} \
        -o {params.out} --unbinned 2> {log.err} 1> {log.out}
        '''

# Use prodigal to find ORFs in the metagenome and save genes and proteins
rule findgenes_prodigal:
    input:
        asm="metaspades/simulated_{sample}.scaf.min1000.fa"
    output:
        fna="genes/{sample}/{sample}_genes.fna",
        faa="genes/{sample}/{sample}_proteins.faa",
        prodi="genes/{sample}/{sample}_prodigal.txt"
    threads: 2
    shell:
        '''
        prodigal -i {input.asm} -p meta -a {output.faa} -d {output.fna} -o {output.prodi}
        '''

# Get stats on assembled MAGs
rule sample_stats:
    input:
        bins = "metabat2/{sample}/{sample}.bin"
    output:
        stats_file = "stats/{sample}.tsv"
    shell:
        '''
        module load ngs tools
        module load openjdk/14
        module load bbmap/38.35
        statswrapper.sh {input.bins}.*.fa > {output.stats_file}
        '''

# Run checkm on the MAGs to estimate taxonomy and quality
rule checkm:
        input:
                check_file = "metabat2/{sample}/{sample}.bin"
        params:
            dir="metabat2/{sample}"
        output:
                txt="checkm/{sample}.checkm.txt",
                dir=directory("checkm/{sample}.checkm")
        threads: 20
        shell:
                '''module load ngs tools
        module unload anaconda3/2.2.0
                module load anaconda2/4.4.0
                module load prodigal/2.6.2
        module load hmmer/3.1b2
        module load pplacer/1.1.alpha17
        checkm lineage_wf -f {output.txt} -t {threads} --pplacer_threads {threads} --tab_table -x fa {params.dir} {output.dir}
        '''

# combine original and MAG'ed genomes
rule pool_bins_and_refs_per_sample:
    input:
        metabat_bins = "metabat2/{sample}/{sample}.bin"
    output:
        all_binned = "bins_all/{sample}/{sample}"
    
    shell: '''
        cp metabat2/{wildcards.sample}/*.bin.*.fa bins_all/{wildcards.sample}/
        cp camisim_fasta_{wildcards.sample}/*.fa bins_all/{wildcards.sample}/
        touch bins_all/{wildcards.sample}/{wildcards.sample}
        '''
        
# Compare genomes to each other using dRep
rule drep_sample:
        input:
            check_file = "bins_all/{sample}/{sample}"
        output:
                test="drep_genomes/{sample}/figures/Secondary_clustering_dendrograms.pdf"
        params:
            indir="bins_all/{sample}",
	        outdir="drep_genomes/{sample}"
        threads: 40
        #threads: 20
        shell:
                '''
                module load tools ngs
                module load mash/2.2
                module load mummer/3.23
                dRep compare {params.outdir} -p {threads} -ms 1000 -g {params.indir}/*fa
                '''

# ### END ADAPTED CODE ###

# Clean up old dRep results
rule cleanup_drep:
    input:
         drep_check = "drep_genomes/{sample}/figures/Secondary_clustering_dendrograms.pdf"
    output:
          check_file = "drep_old/{sample}/{sample}_move_check"

    shell:
         '''
         mv drep_genomes/{wildcards.sample} drep_old/
         touch drep_old/{wildcards.sample}/{wildcards.sample}_move_check
         '''